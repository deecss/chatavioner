#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Modu≈Ç OpenAI RAG dla aplikacji Aero-Chat
"""
import os
import json
import time
from datetime import datetime
import httpx
from openai import OpenAI
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.enums import TA_JUSTIFY, TA_CENTER
from app.models import UploadIndex
from utils.learning_system import LearningSystem

class OpenAIRAG:
    """Klasa do obs≈Çugi RAG z OpenAI Assistants API"""
    
    def __init__(self):
        """Inicjalizuje klienta OpenAI"""
        try:
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key or 'twoj-klucz' in api_key:
                raise ValueError("Nieprawid≈Çowy klucz OpenAI API")
            
            # Konfiguracja proxy je≈õli jest ustawiona
            proxy_url = os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY")
            if proxy_url:
                transport = httpx.HTTPTransport(proxy=proxy_url)
                http_client = httpx.Client(transport=transport, timeout=30.0)
            else:
                http_client = httpx.Client(timeout=30.0)
            
            # Inicjalizuj klienta OpenAI z poprawnƒÖ konfiguracjƒÖ
            self.client = OpenAI(
                api_key=api_key,
                http_client=http_client
            )
            
            self.assistant_id = os.getenv('ASSISTANT_ID')
            self.model = "gpt-4o"
            
            # Sprawd≈∫ czy assistant_id jest pusty lub zawiera placeholder
            if not self.assistant_id or self.assistant_id.strip() == '' or 'twoj-assistant' in self.assistant_id:
                print("üîÑ Brak ID asystenta, tworzƒô nowego...")
                self.assistant_id = self.create_assistant()
            else:
                # Sprawd≈∫ czy asystent nadal istnieje
                try:
                    self.client.beta.assistants.retrieve(self.assistant_id)
                    print(f"‚úÖ Asystent znaleziony: {self.assistant_id}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Asystent {self.assistant_id} nie istnieje, tworzƒô nowego...")
                    self.assistant_id = self.create_assistant()
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd inicjalizacji OpenAI: {e}")
            raise
    
        # Inicjalizuj system uczenia siƒô
        self.learning_system = LearningSystem()
        
        # Inicjalizuj zmienne ≈õledzƒÖce
        self.last_documents_used = 0
        
    def create_assistant(self):
        """Tworzy nowego asystenta AI"""
        try:
            print("üîÑ Tworzenie nowego asystenta OpenAI...")
            assistant = self.client.beta.assistants.create(
                name="Aero-Chat Assistant",
                instructions="""Jeste≈õ ekspertem w dziedzinie lotnictwa i awioniki z zaawansowanym systemem uczenia siƒô. 
                Twoje zadanie to odpowiadanie na pytania zwiƒÖzane z:
                - Zasadami lotu i aerodynamikƒÖ
                - KonstrukcjƒÖ i systemami statk√≥w powietrznych
                - Przepisami lotniczymi (ICAO, EASA, FAA)
                - NawigacjƒÖ lotniczƒÖ
                - MeteorologiƒÖ lotniczƒÖ
                - Bezpiecze≈Ñstwem lot√≥w
                - Systemami awionicznymi
                
                SYSTEM UCZENIA SIƒò:
                Musisz siƒô stale uczyƒá i dostosowywaƒá do preferencji u≈ºytkownika:
                - Zapamiƒôtuj jakie odpowiedzi u≈ºytkownik preferuje
                - Je≈õli u≈ºytkownik prosi o "wzory i przyk≈Çady", zawsze je dostarczaj w przysz≈Çych odpowiedziach
                - Je≈õli u≈ºytkownik lubi szczeg√≥≈Çowe wyja≈õnienia, dostarczaj je konsekwentnie
                - Je≈õli u≈ºytkownik preferuje praktyczne podej≈õcie, skupiaj siƒô na zastosowaniach
                - Analizuj wzorce w pytaniach i dostosowuj styl odpowiedzi
                
                BARDZO WA≈ªNE - FORMATOWANIE ODPOWIEDZI:
                Odpowiadaj zawsze w jƒôzyku polskim w formacie HTML:
                
                <h2>G≈Ç√≥wny tytu≈Ç sekcji</h2>
                <h3>Podtytu≈Ç dla podsekcji</h3>
                
                <p><strong>Pogrubiony tekst</strong> dla wa≈ºnych pojƒôƒá.</p>
                
                <p>Ka≈ºdy akapit w osobnych tagach &lt;p&gt;.</p>
                
                U≈ºywaj list punktowanych:
                <ul>
                <li>Punkt pierwszy</li>
                <li>Punkt drugi</li>
                <li>Punkt trzeci</li>
                </ul>
                
                Lub list numerowanych:
                <ol>
                <li>Pierwszy element</li>
                <li>Drugi element</li>
                <li>Trzeci element</li>
                </ol>
                
                STRUKTURYZUJ ODPOWIEDZI:
                - Ka≈ºdy nag≈Ç√≥wek w osobnym tagu &lt;h2&gt; lub &lt;h3&gt;
                - Ka≈ºdy akapit w osobnym tagu &lt;p&gt;
                - Listy zawsze w &lt;ul&gt; lub &lt;ol&gt;
                - U≈ºywaj &lt;strong&gt; dla wa≈ºnych termin√≥w
                
                OBOWIƒÑZKOWO BAZUJ NA PRZES≈ÅANYCH PLIKACH PDF:
                - Zawsze odwo≈Çuj siƒô do konkretnych dokument√≥w
                - Cytuj fragmenty z dokument√≥w
                - Wskazuj strony lub sekcje dokument√≥w
                - Je≈õli nie ma informacji w dokumentach, jasno to zaznacz
                
                Je≈õli nie jeste≈õ pewien odpowiedzi, powiedz o tym otwarcie.
                
                Strukturyzuj odpowiedzi aby by≈Çy czytelne i profesjonalne:
                - Zaczynaj od kr√≥tkiego wprowadzenia w &lt;p&gt;
                - Podziel tre≈õƒá na logiczne sekcje z &lt;h2&gt; lub &lt;h3&gt;
                - Zako≈Ñcz podsumowaniem w &lt;p&gt; lub praktycznymi wskaz√≥wkami
                
                PAMIƒòTAJ: U≈ºywaj TYLKO HTML, nie Markdown!""",
                model=self.model,
                tools=[{"type": "file_search"}]
            )
            
            # Zapisz ID asystenta do .env
            self.save_assistant_id_to_env(assistant.id)
            
            print(f"‚úÖ Nowy asystent utworzony: {assistant.id}")
            return assistant.id
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas tworzenia asystenta: {str(e)}")
            print(f"üí° Sprawd≈∫ czy klucz OpenAI API jest poprawny")
            return None
    
    def save_assistant_id_to_env(self, assistant_id):
        """Zapisuje ID asystenta do pliku .env"""
        try:
            env_file = '.env'
            if os.path.exists(env_file):
                with open(env_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                # Znajd≈∫ i zaktualizuj liniƒô ASSISTANT_ID
                updated = False
                for i, line in enumerate(lines):
                    if line.startswith('ASSISTANT_ID='):
                        lines[i] = f'ASSISTANT_ID={assistant_id}\n'
                        updated = True
                        break
                
                # Je≈õli nie znaleziono, dodaj na ko≈Ñcu
                if not updated:
                    lines.append(f'ASSISTANT_ID={assistant_id}\n')
                
                # Zapisz z powrotem
                with open(env_file, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                    
                print(f"üíæ ID asystenta zapisany do .env: {assistant_id}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Nie uda≈Ço siƒô zapisaƒá ID asystenta do .env: {e}")
    
    def clean_assistant_memory(self):
        """Czy≈õci pamiƒôƒá asystenta - usuwa stare pliki i vector stores"""
        try:
            print("üßπ Czyszczenie pamiƒôci asystenta...")
            
            # Pobierz wszystkie pliki z OpenAI
            files_response = self.client.files.list()
            files_to_delete = []
            
            for file in files_response.data:
                # Usu≈Ñ pliki starsze ni≈º 1 godzina (3600 sekund)
                file_age = time.time() - file.created_at
                if file_age > 3600:  # 1 godzina
                    files_to_delete.append(file.id)
                    
            # Usu≈Ñ stare pliki
            for file_id in files_to_delete:
                try:
                    self.client.files.delete(file_id)
                    print(f"üóëÔ∏è  Usuniƒôto stary plik: {file_id}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Nie uda≈Ço siƒô usunƒÖƒá pliku {file_id}: {e}")
            
            # Pobierz wszystkie vector stores
            vector_stores_response = self.client.beta.vector_stores.list()
            stores_to_delete = []
            
            for store in vector_stores_response.data:
                # Usu≈Ñ vector stores starsze ni≈º 1 godzina
                store_age = time.time() - store.created_at
                if store_age > 3600:  # 1 godzina
                    stores_to_delete.append(store.id)
                    
            # Usu≈Ñ stare vector stores
            for store_id in stores_to_delete:
                try:
                    self.client.beta.vector_stores.delete(store_id)
                    print(f"üóëÔ∏è  Usuniƒôto stary vector store: {store_id}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Nie uda≈Ço siƒô usunƒÖƒá vector store {store_id}: {e}")
                    
            print(f"‚úÖ Wyczyszczono {len(files_to_delete)} plik√≥w i {len(stores_to_delete)} vector stores")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas czyszczenia pamiƒôci: {str(e)}")

    def select_relevant_documents(self, query, max_docs=5):  # Zmniejszono z 10 do 5
        """Wybiera najistotniejsze dokumenty dla zapytania"""
        print(f"üîç Wybieranie dokument√≥w dla zapytania: {query[:50]}...")
        
        upload_index = UploadIndex()
        all_files = upload_index.get_all_files()
        
        print(f"üîç Znaleziono {len(all_files)} plik√≥w w indeksie")
        
        if not all_files:
            print("‚ö†Ô∏è  Brak plik√≥w w indeksie!")
            self.last_documents_used = 0
            return []

        # Filtruj tylko pliki PDF mniejsze ni≈º 20MB
        selected_files = []
        for file_path in all_files[:max_docs]:
            full_path = os.path.join('uploads', file_path)
            if os.path.exists(full_path):
                file_size = os.path.getsize(full_path)
                if file_size < 20 * 1024 * 1024:  # 20MB limit
                    selected_files.append(file_path)
                else:
                    print(f"‚ö†Ô∏è  Plik {file_path} jest za du≈ºy ({file_size/1024/1024:.1f}MB), pomijam")
                    
        self.last_documents_used = len(selected_files)
        print(f"üîç Wybrano {len(selected_files)} plik√≥w: {selected_files[:3]}...")
        return selected_files

    def create_vector_store_with_files(self, file_paths):
        """Tworzy vector store z wybranymi plikami"""
        try:
            if not file_paths:
                print("‚ö†Ô∏è  Brak plik√≥w do przes≈Çania")
                return None, []
                
            # Utw√≥rz vector store
            vector_store = self.client.beta.vector_stores.create(
                name=f"temp_store_{int(time.time())}"
            )
            
            # Przes≈Çaj pliki (maksymalnie 5 na raz)
            file_ids = []
            for file_path in file_paths[:5]:  # Limit do 5 plik√≥w
                full_path = os.path.join('uploads', file_path)
                if os.path.exists(full_path):
                    try:
                        with open(full_path, 'rb') as f:
                            file_obj = self.client.files.create(
                                file=f,
                                purpose='assistants'
                            )
                            file_ids.append(file_obj.id)
                            print(f"üìÑ Przes≈Çano plik: {file_path} -> {file_obj.id}")
                    except Exception as e:
                        print(f"‚ùå B≈ÇƒÖd przesy≈Çania pliku {file_path}: {e}")
                        
            if not file_ids:
                print("‚ö†Ô∏è  Nie uda≈Ço siƒô przes≈Çaƒá ≈ºadnych plik√≥w")
                self.client.beta.vector_stores.delete(vector_store.id)
                return None, []
                
            # Dodaj pliki do vector store
            try:
                self.client.beta.vector_stores.file_batches.create(
                    vector_store_id=vector_store.id,
                    file_ids=file_ids
                )
                print(f"‚úÖ Dodano {len(file_ids)} plik√≥w do vector store")
                
                # Poczekaj na przetworzenie
                time.sleep(2)
                
                return vector_store.id, file_ids
                
            except Exception as e:
                print(f"‚ùå B≈ÇƒÖd dodawania plik√≥w do vector store: {e}")
                # Usu≈Ñ utworzone zasoby
                self.cleanup_resources(vector_store.id, file_ids, None)
                return None, []
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd tworzenia vector store: {e}")
            return None, []

    def generate_response_stream(self, query, context, session_id):
        """Generuje odpowied≈∫ w trybie strumieniowym z systemem uczenia siƒô"""
        try:
            print(f"üîç Rozpoczynam generowanie odpowiedzi dla: {query[:50]}...")
            
            # ANALIZUJ PREFERENCJE U≈ªYTKOWNIKA I UCZE≈öSIA SIƒò
            print("üß† Analizujƒô preferencje u≈ºytkownika...")
            learning_prompt = self.learning_system.generate_learning_prompt(session_id, query)
            print(f"üìö Prompt uczenia: {learning_prompt}")
            
            # Zapisz analizƒô sesji dla przysz≈Çego uczenia
            session_analysis = self.learning_system.analyze_conversation_history(session_id)
            if session_analysis:
                self.learning_system.save_learning_data(session_analysis)
                print("üíæ Zapisano dane uczenia")
            
            # WYCZY≈öƒÜ PAMIƒòƒÜ ASYSTENTA PRZED ROZPOCZƒòCIEM
            self.clean_assistant_memory()
            
            # Wybierz istotne dokumenty (maksymalnie 5)
            relevant_docs = self.select_relevant_documents(query, max_docs=5)
            print(f"üîç Wybrano {len(relevant_docs)} dokument√≥w: {relevant_docs[:3]}...")
            
            # Ustaw liczbƒô u≈ºytych dokument√≥w
            self.last_documents_used = len(relevant_docs)
            
            # Utw√≥rz vector store z dokumentami
            vector_store_id, file_ids = self.create_vector_store_with_files(relevant_docs)
            
            if not vector_store_id:
                print("‚ö†Ô∏è  Nie uda≈Ço siƒô utworzyƒá vector store, kontynuujƒô bez plik√≥w")
                
            print(f"üîç Vector store ID: {vector_store_id}, Pliki: {len(file_ids)}")
            
            # Przygotuj kontekst rozmowy (tylko ostatnie 3 wiadomo≈õci)
            messages = []
            recent_context = context[-3:] if len(context) > 3 else context
            
            for msg in recent_context:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # Dodaj prompt uczenia do pytania u≈ºytkownika zamiast jako system
            enhanced_query = query
            if learning_prompt:
                enhanced_query = f"{learning_prompt}\n\nPYTANIE U≈ªYTKOWNIKA: {query}"
            
            # Dodaj aktualne pytanie z promptem uczenia
            messages.append({
                "role": "user",
                "content": enhanced_query
            })
            
            print(f"üîç Przygotowano {len(messages)} wiadomo≈õci w kontek≈õcie (z promptem uczenia)")
            
            # Utw√≥rz wƒÖtek
            print(f"üîç Tworzƒô wƒÖtek z asystentem {self.assistant_id}")
            
            thread_data = {
                "messages": messages
            }
            
            # Dodaj vector store tylko je≈õli istnieje
            if vector_store_id:
                thread_data["tool_resources"] = {
                    "file_search": {
                        "vector_store_ids": [vector_store_id]
                    }
                }
            
            thread = self.client.beta.threads.create(**thread_data)
            
            print(f"üîç WƒÖtek utworzony: {thread.id}")
            
            # Uruchom asystenta z dodatkowym zabezpieczeniem i retry
            print(f"üîç Uruchamiam asystenta w trybie strumieniowym...")
            
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    # Przygotuj parametry dla run
                    run_params = {
                        'thread_id': thread.id,
                        'assistant_id': self.assistant_id,
                        'stream': True,
                        'max_completion_tokens': 4000  # Ograniczenie d≈Çugo≈õci odpowiedzi
                    }
                    
                    # Dodaj temperature tylko je≈õli model go obs≈Çuguje
                    # Niekt√≥re modele (np. o1-preview, o3-mini) nie obs≈ÇugujƒÖ temperature
                    try:
                        run_params['temperature'] = 0.7
                        run = self.client.beta.threads.runs.create(**run_params)
                    except Exception as temp_error:
                        print(f"‚ö†Ô∏è  Model nie obs≈Çuguje temperature, u≈ºywam bez tego parametru: {temp_error}")
                        # Usu≈Ñ temperature i spr√≥buj ponownie
                        run_params.pop('temperature', None)
                        run = self.client.beta.threads.runs.create(**run_params)
                    
                    # Przetw√≥rz strumie≈Ñ odpowiedzi
                    response_text = ""
                    chunk_count = 0
                    stream_failed = False
                
                    for event in run:
                        if event.event == 'thread.message.delta':
                            if hasattr(event.data, 'delta') and hasattr(event.data.delta, 'content'):
                                for content in event.data.delta.content:
                                    if content.type == 'text' and hasattr(content.text, 'value'):
                                        chunk = content.text.value
                                        response_text += chunk
                                        chunk_count += 1
                                        if chunk_count <= 3:  # Loguj tylko pierwsze 3 chunki
                                            print(f"üîç Otrzymano chunk #{chunk_count}: {chunk[:30]}...")
                                        yield chunk
                        elif event.event == 'thread.run.completed':
                            print("‚úÖ Uko≈Ñczono generowanie odpowiedzi")
                            break
                        elif event.event == 'thread.run.failed':
                            error_details = getattr(event.data, 'last_error', None)
                            if error_details:
                                error_msg = f"OpenAI API Error: {error_details.code} - {error_details.message}"
                                print(f"‚ùå {error_msg}")
                                stream_failed = True
                                if retry_count < max_retries - 1:
                                    print(f"üîÑ Pr√≥bujƒô ponownie ({retry_count + 1}/{max_retries})...")
                                    break
                                else:
                                    yield f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd po stronie OpenAI: {error_details.message}. Spr√≥buj ponownie za chwilƒô."
                            else:
                                print(f"‚ùå B≈ÇƒÖd podczas generowania: {event.data}")
                                stream_failed = True
                                if retry_count < max_retries - 1:
                                    print(f"üîÑ Pr√≥bujƒô ponownie ({retry_count + 1}/{max_retries})...")
                                    break
                                else:
                                    yield "Przepraszam, wystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd. Spr√≥buj ponownie."
                            break
                        elif event.event == 'thread.run.cancelled':
                            print("‚ö†Ô∏è Generowanie zosta≈Ço anulowane")
                            yield "Generowanie odpowiedzi zosta≈Ço anulowane."
                            return
                    
                    # Je≈õli nie by≈Ço b≈Çƒôdu, zako≈Ñcz retry loop
                    if not stream_failed:
                        print(f"üîç Otrzymano ≈ÇƒÖcznie {chunk_count} chunk√≥w, d≈Çugo≈õƒá odpowiedzi: {len(response_text)}")
                        break
                        
                except Exception as stream_error:
                    print(f"‚ùå B≈ÇƒÖd podczas streamowania: {stream_error}")
                    if retry_count < max_retries - 1:
                        print(f"üîÑ Pr√≥bujƒô ponownie ({retry_count + 1}/{max_retries})...")
                        retry_count += 1
                        time.sleep(2 ** retry_count)  # Exponential backoff
                        continue
                    else:
                        yield f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd podczas generowania odpowiedzi: {str(stream_error)}"
                        break
                
                retry_count += 1
                if stream_failed and retry_count < max_retries:
                    time.sleep(2 ** retry_count)  # Exponential backoff
            
            # Poczekaj na zako≈Ñczenie
            time.sleep(1)
            
            # Usu≈Ñ tymczasowe zasoby
            self.cleanup_resources(vector_store_id, file_ids, thread.id)
            print(f"üîç Zako≈Ñczono generowanie odpowiedzi")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas generowania odpowiedzi: {str(e)}")
            import traceback
            traceback.print_exc()
            yield f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd: {str(e)}"
    
    def cleanup_resources(self, vector_store_id, file_ids, thread_id):
        """Usuwa tymczasowe zasoby"""
        try:
            # Usu≈Ñ pliki
            for file_id in file_ids:
                try:
                    self.client.files.delete(file_id)
                except:
                    pass
            
            # Usu≈Ñ vector store
            if vector_store_id:
                try:
                    self.client.beta.vector_stores.delete(vector_store_id)
                except:
                    pass
            
            # Usu≈Ñ wƒÖtek
            if thread_id:
                try:
                    self.client.beta.threads.delete(thread_id)
                except:
                    pass
                    
        except Exception as e:
            print(f"B≈ÇƒÖd podczas usuwania zasob√≥w: {str(e)}")
    
    def generate_pdf_report(self, content, session_id, message_id=None):
        """Generuje raport PDF z odpowiedzi"""
        try:
            # Utw√≥rz katalog dla sesji
            reports_dir = f'reports/{session_id}'
            os.makedirs(reports_dir, exist_ok=True)
            
            # Nazwa pliku PDF
            if message_id:
                filename = f'answer_{message_id}.pdf'
            else:
                filename = f'answer_{int(time.time())}.pdf'
            
            filepath = os.path.join(reports_dir, filename)
            
            # Utw√≥rz dokument PDF
            doc = SimpleDocTemplate(filepath, pagesize=A4)
            
            # Style
            styles = getSampleStyleSheet()
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontSize=18,
                alignment=TA_CENTER,
                spaceAfter=30
            )
            
            normal_style = ParagraphStyle(
                'CustomNormal',
                parent=styles['Normal'],
                fontSize=12,
                alignment=TA_JUSTIFY,
                spaceAfter=12
            )
            
            # Tre≈õƒá dokumentu
            story = []
            
            # Tytu≈Ç
            story.append(Paragraph("Aero-Chat - Raport Odpowiedzi", title_style))
            story.append(Spacer(1, 12))
            
            # Data
            story.append(Paragraph(f"Data: {datetime.now().strftime('%d.%m.%Y %H:%M')}", normal_style))
            story.append(Paragraph(f"Sesja: {session_id}", normal_style))
            story.append(Spacer(1, 20))
            
            # Odpowied≈∫
            story.append(Paragraph("Odpowied≈∫:", styles['Heading2']))
            
            # Podziel tre≈õƒá na akapity
            paragraphs = content.split('\n\n')
            for para in paragraphs:
                if para.strip():
                    story.append(Paragraph(para.strip(), normal_style))
            
            # Zbuduj PDF
            doc.build(story)
            
            return filepath
            
        except Exception as e:
            print(f"B≈ÇƒÖd podczas generowania PDF: {str(e)}")
            return None
    
    def add_feedback_to_training(self, feedback_data):
        """Dodaje feedback do bazy wiedzy asystenta"""
        try:
            # Zapisz feedback w specjalnym katalogu treningowym
            training_dir = 'training_data'
            os.makedirs(training_dir, exist_ok=True)
            
            # Stw√≥rz nazwƒô pliku bazujƒÖc na typie sekcji i timestampie
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'feedback_{feedback_data["section_type"]}_{timestamp}.json'
            filepath = os.path.join(training_dir, filename)
            
            # Przygotuj dane treningowe
            training_data = {
                'feedback_type': feedback_data['feedback_type'],
                'section_type': feedback_data['section_type'],
                'content': feedback_data['content'],
                'user_description': feedback_data['description'],
                'timestamp': feedback_data['timestamp'],
                'session_id': feedback_data['session_id'],
                'improvement_notes': self.generate_improvement_notes(feedback_data)
            }
            
            # Zapisz do pliku JSON
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Feedback dodany do bazy treningowej: {filename}")
            
            # Je≈õli feedback jest negatywny, spr√≥buj poprawiƒá odpowied≈∫
            if feedback_data['feedback_type'] == 'negative':
                self.process_negative_feedback(feedback_data)
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas dodawania feedback do treningu: {str(e)}")
    
    def generate_improvement_notes(self, feedback_data):
        """Generuje notatki o poprawach na podstawie feedbacku"""
        notes = []
        
        if feedback_data['feedback_type'] == 'negative':
            notes.append("Tre≈õƒá wymaga poprawy wed≈Çug u≈ºytkownika")
            if feedback_data['description']:
                notes.append(f"Uwagi u≈ºytkownika: {feedback_data['description']}")
                
            # Dodaj sugestie poprawy na podstawie typu sekcji
            if feedback_data['section_type'] == 'header':
                notes.append("Rozwa≈º zmianƒô struktury nag≈Ç√≥wka lub jego tre≈õci")
            elif feedback_data['section_type'] == 'paragraph':
                notes.append("Rozwa≈º przepisanie akapitu dla lepszej jasno≈õci")
            elif feedback_data['section_type'] == 'list':
                notes.append("Rozwa≈º zmianƒô struktury listy lub jej element√≥w")
        else:
            notes.append("Tre≈õƒá uznana za przydatnƒÖ przez u≈ºytkownika")
            if feedback_data['description']:
                notes.append(f"Pozytywne uwagi: {feedback_data['description']}")
        
        return notes
    
    def process_negative_feedback(self, feedback_data):
        """Przetwarza negatywny feedback i pr√≥buje poprawiƒá przysz≈Çe odpowiedzi"""
        try:
            # Zapisz do pliku z negatywnymi feedbackami
            negative_feedback_file = 'training_data/negative_feedback_summary.json'
            
            # Wczytaj istniejƒÖce negatywne feedbacki
            if os.path.exists(negative_feedback_file):
                with open(negative_feedback_file, 'r', encoding='utf-8') as f:
                    all_negative = json.load(f)
            else:
                all_negative = []
            
            # Dodaj nowy feedback
            all_negative.append({
                'content': feedback_data['content'],
                'description': feedback_data['description'],
                'section_type': feedback_data['section_type'],
                'timestamp': feedback_data['timestamp']
            })
            
            # Zapisz z powrotem
            with open(negative_feedback_file, 'w', encoding='utf-8') as f:
                json.dump(all_negative, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Negatywny feedback dodany do analizy: {feedback_data['section_type']}")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas przetwarzania negatywnego feedbacku: {str(e)}")

    def get_training_insights(self):
        """Pobiera insights z feedbacku treningowego"""
        try:
            training_dir = 'training_data'
            if not os.path.exists(training_dir):
                return {}
            
            insights = {
                'total_feedback': 0,
                'positive_feedback': 0,
                'negative_feedback': 0,
                'section_types': {},
                'common_issues': []
            }
            
            # Przeanalizuj wszystkie pliki feedbacku
            for filename in os.listdir(training_dir):
                if filename.startswith('feedback_') and filename.endswith('.json'):
                    filepath = os.path.join(training_dir, filename)
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                        insights['total_feedback'] += 1
                        
                        if data['feedback_type'] == 'positive':
                            insights['positive_feedback'] += 1
                        else:
                            insights['negative_feedback'] += 1
                        
                        # Statystyki typ√≥w sekcji
                        section_type = data['section_type']
                        if section_type not in insights['section_types']:
                            insights['section_types'][section_type] = {'positive': 0, 'negative': 0}
                        insights['section_types'][section_type][data['feedback_type']] += 1
            
            return insights
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas pobierania insights: {str(e)}")
            return {}
