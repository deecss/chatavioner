#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Modu≈Ç OpenAI RAG dla aplikacji Aero-Chat
"""
import os
import json
import time
from datetime import datetime
import httpx
from openai import OpenAI
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.enums import TA_JUSTIFY, TA_CENTER
from app.models import UploadIndex
from utils.learning_system import LearningSystem

class OpenAIRAG:
    """Klasa do obs≈Çugi RAG z OpenAI Assistants API"""
    
    def __init__(self):
        """Inicjalizuje klienta OpenAI"""
        try:
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key or 'twoj-klucz' in api_key:
                raise ValueError("Nieprawid≈Çowy klucz OpenAI API")
            
            # Konfiguracja proxy je≈õli jest ustawiona
            proxy_url = os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY")
            if proxy_url:
                transport = httpx.HTTPTransport(proxy=proxy_url)
                http_client = httpx.Client(transport=transport, timeout=30.0)
            else:
                http_client = httpx.Client(timeout=30.0)
            
            # Inicjalizuj klienta OpenAI z poprawnƒÖ konfiguracjƒÖ
            self.client = OpenAI(
                api_key=api_key,
                http_client=http_client
            )
            
            self.assistant_id = os.getenv('ASSISTANT_ID')
            self.model = "gpt-4o"
            
            # Sprawd≈∫ czy assistant_id jest pusty lub zawiera placeholder
            if not self.assistant_id or self.assistant_id.strip() == '' or 'twoj-assistant' in self.assistant_id:
                print("üîÑ Brak ID asystenta, tworzƒô nowego...")
                self.assistant_id = self.create_assistant()
            else:
                # Sprawd≈∫ czy asystent nadal istnieje
                try:
                    self.client.beta.assistants.retrieve(self.assistant_id)
                    print(f"‚úÖ Asystent znaleziony: {self.assistant_id}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Asystent {self.assistant_id} nie istnieje, tworzƒô nowego...")
                    self.assistant_id = self.create_assistant()
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd inicjalizacji OpenAI: {e}")
            raise
    
        # Inicjalizuj system uczenia siƒô
        self.learning_system = LearningSystem()
        
        # Inicjalizuj zmienne ≈õledzƒÖce
        self.last_documents_used = 0
        
    def create_assistant(self):
        """Tworzy nowego asystenta AI"""
        try:
            print("üîÑ Tworzenie nowego asystenta OpenAI...")
            assistant = self.client.beta.assistants.create(
                name="Aero-Chat Assistant",
                instructions="""Jeste≈õ ekspertem w dziedzinie lotnictwa i awioniki z zaawansowanym systemem uczenia siƒô. 
                
                üö® SUROWE OGRANICZENIE TEMATYCZNE:
                ODPOWIADASZ WY≈ÅƒÑCZNIE NA PYTANIA Z DZIEDZINY LOTNICTWA!
                
                Tematy dozwolone:
                - Zasady lotu i aerodynamika
                - Konstrukcja i systemy statk√≥w powietrznych
                - Przepisy lotnicze (ICAO, EASA, FAA, polskie)
                - Nawigacja lotnicza
                - Meteorologia lotnicza
                - Bezpiecze≈Ñstwo lot√≥w
                - Systemy awioniczne
                - Historia lotnictwa
                - Licencje pilota
                - Procedury lotnicze
                - Komunikacja lotnicza
                - Planowanie lot√≥w
                - Operacje lotniskowe
                - Szkolenia lotnicze
                - Certyfikacja lotnicza
                - Maintenance i obs≈Çuga techniczna
                - Wsp√≥≈Çczesne technologie lotnicze
                
                ‚ùå KATEGORYCZNIE ODRZUCAJ pytania o:
                - Tematykƒô niezwiƒÖzanƒÖ z lotnictwem
                - Inne rodzaje transportu (samochody, pociƒÖgi, statki)
                - Politykƒô, ekonomiƒô (chyba ≈ºe bezpo≈õrednio zwiƒÖzane z lotnictwem)
                - Medycynƒô (chyba ≈ºe medycyna lotnicza)
                - Inne dziedziny nauki i techniki
                - Rozrywkƒô, filmy, gry
                - ≈ªycie osobiste, porady ≈ºyciowe
                - Inne tematy spoza lotnictwa
                
                üõë REAKCJA NA PYTANIA SPOZA LOTNICTWA:
                Je≈õli pytanie nie dotyczy lotnictwa, odpowiedz DOK≈ÅADNIE:
                
                "<p><strong>Przepraszam, ale jestem wyspecjalizowanym asystentem lotniczym.</strong></p>
                <p>Mogƒô odpowiadaƒá wy≈ÇƒÖcznie na pytania zwiƒÖzane z lotnictwem, awionik, przepisami lotniczymi, nawigacjƒÖ, meteorologiƒÖ lotniczƒÖ, bezpiecze≈Ñstwem lot√≥w i zwiƒÖzanymi tematami.</p>
                <p>Proszƒô zadaj pytanie dotyczƒÖce lotnictwa, a chƒôtnie pomogƒô!</p>"
                
                ‚ö†Ô∏è BARDZO WA≈ªNE - PAMIƒòƒÜ ROZMOWY:
                - ZAWSZE czytaj i analizuj ca≈ÇƒÖ historiƒô rozmowy
                - Je≈õli u≈ºytkownik zadaje to samo pytanie ponownie, odwo≈Çaj siƒô do wcze≈õniejszej odpowiedzi
                - Je≈õli u≈ºytkownik prosi o wiƒôcej szczeg√≥≈Ç√≥w, rozbuduj poprzedniƒÖ odpowied≈∫
                - Je≈õli u≈ºytkownik zadaje pytanie kontynuujƒÖce temat, podejmij wƒÖtek z wcze≈õniejszej rozmowy
                - Pamiƒôtaj preferencje u≈ºytkownika z poprzednich odpowiedzi
                
                SYSTEM UCZENIA SIƒò:
                Musisz siƒô stale uczyƒá i dostosowywaƒá do preferencji u≈ºytkownika:
                - Zapamiƒôtuj jakie odpowiedzi u≈ºytkownik preferuje
                - Je≈õli u≈ºytkownik prosi o "wzory i przyk≈Çady", zawsze je dostarczaj w przysz≈Çych odpowiedziach
                - Je≈õli u≈ºytkownik lubi szczeg√≥≈Çowe wyja≈õnienia, dostarczaj je konsekwentnie
                - Je≈õli u≈ºytkownik preferuje praktyczne podej≈õcie, skupiaj siƒô na zastosowaniach
                - Analizuj wzorce w pytaniach i dostosowuj styl odpowiedzi
                
                BARDZO WA≈ªNE - FORMATOWANIE ODPOWIEDZI:
                Odpowiadaj zawsze w jƒôzyku polskim w formacie HTML:
                
                <h2>G≈Ç√≥wny tytu≈Ç sekcji</h2>
                <h3>Podtytu≈Ç dla podsekcji</h3>
                
                <p><strong>Pogrubiony tekst</strong> dla wa≈ºnych pojƒôƒá.</p>
                
                <p>Ka≈ºdy akapit w osobnych tagach &lt;p&gt;.</p>
                
                U≈ºywaj list punktowanych:
                <ul>
                <li>Punkt pierwszy</li>
                <li>Punkt drugi</li>
                <li>Punkt trzeci</li>
                </ul>
                
                Lub list numerowanych:
                <ol>
                <li>Pierwszy element</li>
                <li>Drugi element</li>
                <li>Trzeci element</li>
                </ol>
                
                STRUKTURYZUJ ODPOWIEDZI:
                - Ka≈ºdy nag≈Ç√≥wek w osobnym tagu &lt;h2&gt; lub &lt;h3&gt;
                - Ka≈ºdy akapit w osobnym tagu &lt;p&gt;
                - Listy zawsze w &lt;ul&gt; lub &lt;ol&gt;
                - U≈ºywaj &lt;strong&gt; dla wa≈ºnych termin√≥w
                
                OBOWIƒÑZKOWO BAZUJ NA PRZES≈ÅANYCH PLIKACH PDF:
                - Zawsze odwo≈Çuj siƒô do konkretnych dokument√≥w
                - Cytuj fragmenty z dokument√≥w
                - Wskazuj strony lub sekcje dokument√≥w
                - Je≈õli nie ma informacji w dokumentach, jasno to zaznacz
                
                Je≈õli nie jeste≈õ pewien odpowiedzi, powiedz o tym otwarcie.
                
                Strukturyzuj odpowiedzi aby by≈Çy czytelne i profesjonalne:
                - Zaczynaj od kr√≥tkiego wprowadzenia w &lt;p&gt;
                - Podziel tre≈õƒá na logiczne sekcje z &lt;h2&gt; lub &lt;h3&gt;
                - Zako≈Ñcz podsumowaniem w &lt;p&gt; lub praktycznymi wskaz√≥wkami
                
                PAMIƒòTAJ: U≈ºywaj TYLKO HTML, nie Markdown!""",
                model=self.model,
                tools=[{"type": "file_search"}]
            )
            
            # Zapisz ID asystenta do .env
            self.save_assistant_id_to_env(assistant.id)
            
            print(f"‚úÖ Nowy asystent utworzony: {assistant.id}")
            return assistant.id
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas tworzenia asystenta: {str(e)}")
            print(f"üí° Sprawd≈∫ czy klucz OpenAI API jest poprawny")
            return None
    
    def save_assistant_id_to_env(self, assistant_id):
        """Zapisuje ID asystenta do pliku .env"""
        try:
            env_file = '.env'
            if os.path.exists(env_file):
                with open(env_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                # Znajd≈∫ i zaktualizuj liniƒô ASSISTANT_ID
                updated = False
                for i, line in enumerate(lines):
                    if line.startswith('ASSISTANT_ID='):
                        lines[i] = f'ASSISTANT_ID={assistant_id}\n'
                        updated = True
                        break
                
                # Je≈õli nie znaleziono, dodaj na ko≈Ñcu
                if not updated:
                    lines.append(f'ASSISTANT_ID={assistant_id}\n')
                
                # Zapisz z powrotem
                with open(env_file, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                    
                print(f"üíæ ID asystenta zapisany do .env: {assistant_id}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Nie uda≈Ço siƒô zapisaƒá ID asystenta do .env: {e}")
    
    def clean_assistant_memory(self):
        """Czy≈õci pamiƒôƒá asystenta - usuwa stare pliki i vector stores"""
        try:
            print("üßπ Czyszczenie pamiƒôci asystenta...")
            
            # Pobierz wszystkie pliki z OpenAI
            files_response = self.client.files.list()
            files_to_delete = []
            
            for file in files_response.data:
                # Usu≈Ñ pliki starsze ni≈º 1 godzina (3600 sekund)
                file_age = time.time() - file.created_at
                if file_age > 3600:  # 1 godzina
                    files_to_delete.append(file.id)
                    
            # Usu≈Ñ stare pliki
            for file_id in files_to_delete:
                try:
                    self.client.files.delete(file_id)
                    print(f"üóëÔ∏è  Usuniƒôto stary plik: {file_id}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Nie uda≈Ço siƒô usunƒÖƒá pliku {file_id}: {e}")
            
            # Pobierz wszystkie vector stores
            vector_stores_response = self.client.beta.vector_stores.list()
            stores_to_delete = []
            
            for store in vector_stores_response.data:
                # Usu≈Ñ vector stores starsze ni≈º 1 godzina
                store_age = time.time() - store.created_at
                if store_age > 3600:  # 1 godzina
                    stores_to_delete.append(store.id)
                    
            # Usu≈Ñ stare vector stores
            for store_id in stores_to_delete:
                try:
                    self.client.beta.vector_stores.delete(store_id)
                    print(f"üóëÔ∏è  Usuniƒôto stary vector store: {store_id}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Nie uda≈Ço siƒô usunƒÖƒá vector store {store_id}: {e}")
                    
            print(f"‚úÖ Wyczyszczono {len(files_to_delete)} plik√≥w i {len(stores_to_delete)} vector stores")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas czyszczenia pamiƒôci: {str(e)}")

    def cancel_active_runs(self, thread_id):
        """Anuluje wszystkie aktywne runy w wƒÖtku"""
        try:
            print(f"üîç Sprawdzam aktywne runy w wƒÖtku {thread_id}")
            
            # Pobierz wszystkie runy w wƒÖtku
            runs = self.client.beta.threads.runs.list(thread_id=thread_id)
            
            active_runs = []
            for run in runs.data:
                if run.status in ['queued', 'in_progress', 'requires_action']:
                    active_runs.append(run.id)
                    
            # Anuluj aktywne runy
            for run_id in active_runs:
                try:
                    self.client.beta.threads.runs.cancel(thread_id=thread_id, run_id=run_id)
                    print(f"‚ö†Ô∏è  Anulowano aktywny run: {run_id}")
                except Exception as e:
                    print(f"‚ùå Nie uda≈Ço siƒô anulowaƒá run {run_id}: {e}")
                    
            if active_runs:
                print(f"‚úÖ Anulowano {len(active_runs)} aktywnych run√≥w")
                time.sleep(1)  # Kr√≥tkie op√≥≈∫nienie aby anulowanie siƒô doko≈Ñczy≈Ço
            else:
                print("‚úÖ Brak aktywnych run√≥w do anulowania")
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas anulowania aktywnych run√≥w: {str(e)}")

    def select_relevant_documents(self, query, max_docs=5):  # Zmniejszono z 10 do 5
        """Wybiera najistotniejsze dokumenty dla zapytania"""
        print(f"üîç Wybieranie dokument√≥w dla zapytania: {query[:50]}...")
        
        upload_index = UploadIndex()
        all_files = upload_index.get_all_files()
        
        print(f"üîç Znaleziono {len(all_files)} plik√≥w w indeksie")
        
        if not all_files:
            print("‚ö†Ô∏è  Brak plik√≥w w indeksie!")
            self.last_documents_used = 0
            return []

        # Filtruj tylko pliki PDF mniejsze ni≈º 20MB
        selected_files = []
        for file_path in all_files[:max_docs]:
            full_path = os.path.join('uploads', file_path)
            if os.path.exists(full_path):
                file_size = os.path.getsize(full_path)
                if file_size < 20 * 1024 * 1024:  # 20MB limit
                    selected_files.append(file_path)
                else:
                    print(f"‚ö†Ô∏è  Plik {file_path} jest za du≈ºy ({file_size/1024/1024:.1f}MB), pomijam")
                    
        self.last_documents_used = len(selected_files)
        print(f"üîç Wybrano {len(selected_files)} plik√≥w: {selected_files[:3]}...")
        return selected_files

    def create_vector_store_with_files(self, file_paths):
        """Tworzy vector store z wybranymi plikami"""
        try:
            if not file_paths:
                print("‚ö†Ô∏è  Brak plik√≥w do przes≈Çania")
                return None, []
                
            # Utw√≥rz vector store
            vector_store = self.client.beta.vector_stores.create(
                name=f"temp_store_{int(time.time())}"
            )
            
            # Przes≈Çaj pliki (maksymalnie 5 na raz)
            file_ids = []
            for file_path in file_paths[:5]:  # Limit do 5 plik√≥w
                full_path = os.path.join('uploads', file_path)
                if os.path.exists(full_path):
                    try:
                        with open(full_path, 'rb') as f:
                            file_obj = self.client.files.create(
                                file=f,
                                purpose='assistants'
                            )
                            file_ids.append(file_obj.id)
                            print(f"üìÑ Przes≈Çano plik: {file_path} -> {file_obj.id}")
                    except Exception as e:
                        print(f"‚ùå B≈ÇƒÖd przesy≈Çania pliku {file_path}: {e}")
                        
            if not file_ids:
                print("‚ö†Ô∏è  Nie uda≈Ço siƒô przes≈Çaƒá ≈ºadnych plik√≥w")
                self.client.beta.vector_stores.delete(vector_store.id)
                return None, []
                
            # Dodaj pliki do vector store
            try:
                self.client.beta.vector_stores.file_batches.create(
                    vector_store_id=vector_store.id,
                    file_ids=file_ids
                )
                print(f"‚úÖ Dodano {len(file_ids)} plik√≥w do vector store")
                
                # Poczekaj na przetworzenie
                time.sleep(2)
                
                return vector_store.id, file_ids
                
            except Exception as e:
                print(f"‚ùå B≈ÇƒÖd dodawania plik√≥w do vector store: {e}")
                # Usu≈Ñ utworzone zasoby
                self.cleanup_resources(vector_store.id, file_ids, None)
                return None, []
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd tworzenia vector store: {e}")
            return None, []

    def generate_response_stream(self, query, context, session_id):
        """Generuje odpowied≈∫ w trybie strumieniowym z systemem uczenia siƒô"""
        try:
            print(f"üîç Rozpoczynam generowanie odpowiedzi dla: {query[:50]}...")
            
            # Sprawd≈∫ czy pytanie dotyczy lotnictwa (sprawdzenie na poziomie aplikacji)
            if not self.is_aviation_related(query):
                print(f"‚ö†Ô∏è  Pytanie nie dotyczy lotnictwa: {query[:100]}...")
                rejection_message = ("Przepraszam, ale jestem asystentem specjalizujƒÖcym siƒô wy≈ÇƒÖcznie w tematyce lotniczej. "
                                   "Mogƒô pom√≥c w nastƒôpujƒÖcych obszarach:\n"
                                   "- Pilota≈º i procedury lotnicze\n"
                                   "- Aerodynamika i mechanika lotu\n"
                                   "- Nawigacja i komunikacja\n"
                                   "- Meteorologia lotnicza\n"
                                   "- Przepisy i certyfikacja\n"
                                   "- Bezpiecze≈Ñstwo lot√≥w\n"
                                   "- Awionika i systemy pok≈Çadowe\n"
                                   "- Maintenance i serwis\n\n"
                                   "Proszƒô zadaƒá pytanie zwiƒÖzane z lotnictwem.")
                
                # Zwr√≥ƒá odpowied≈∫ jako generator dla zachowania zgodno≈õci
                def rejection_generator():
                    print(f"üö´ Zwracam wiadomo≈õƒá odmowy: {rejection_message[:100]}...")
                    yield rejection_message
                
                return rejection_generator()
            
            # WyciƒÖgnij user_id z kontekstu (je≈õli dostƒôpny)
            user_id = None
            if context:
                # Znajd≈∫ pierwszƒÖ wiadomo≈õƒá z user_id
                for msg in context:
                    if isinstance(msg, dict) and 'user_id' in msg:
                        user_id = msg['user_id']
                        break
            
            print(f"üÜî User ID z kontekstu: {user_id}")
            
            # ANALIZUJ PREFERENCJE U≈ªYTKOWNIKA I UCZE≈öSIA
            print("üß† Analizujƒô preferencje u≈ºytkownika...")
            learning_prompt = self.learning_system.generate_learning_prompt(session_id, query, user_id)
            print(f"üìö Prompt uczenia: {learning_prompt}")
            
            # Zapisz analizƒô sesji dla przysz≈Çego uczenia
            session_analysis = self.learning_system.analyze_conversation_history(session_id, user_id)
            if session_analysis:
                self.learning_system.save_learning_data(session_analysis)
                print("üíæ Zapisano dane uczenia")
            
            # WYCZY≈öƒÜ PAMIƒòƒÜ ASYSTENTA PRZED ROZPOCZƒòCIEM
            self.clean_assistant_memory()
            
            # Wybierz istotne dokumenty (maksymalnie 5)
            relevant_docs = self.select_relevant_documents(query, max_docs=5)
            print(f"üîç Wybrano {len(relevant_docs)} dokument√≥w: {relevant_docs[:3]}...")
            
            # Ustaw liczbƒô u≈ºytych dokument√≥w
            self.last_documents_used = len(relevant_docs)
            
            # Utw√≥rz vector store z dokumentami
            vector_store_id, file_ids = self.create_vector_store_with_files(relevant_docs)
            
            if not vector_store_id:
                print("‚ö†Ô∏è  Nie uda≈Ço siƒô utworzyƒá vector store, kontynuujƒô bez plik√≥w")
                
            print(f"üîç Vector store ID: {vector_store_id}, Pliki: {len(file_ids)}")
            
            # Przygotuj kontekst rozmowy (pe≈Çna historia, zwiƒôksz do 30 wiadomo≈õci)
            messages = []
            # Zwiƒôksz kontekst do 30 ostatnich wiadomo≈õci (15 par pytanie-odpowied≈∫)
            recent_context = context[-30:] if len(context) > 30 else context
            
            print(f"üîç Przygotowujƒô kontekst z {len(recent_context)} wiadomo≈õci (z {len(context)} ca≈Çkowitych)")
            print(f"üìö Pierwsze pytanie w sesji: {context[0]['content'][:100] if context else 'Brak kontekstu'}...")
            print(f"üìö Ostatnie pytanie w sesji: {context[-1]['content'][:100] if context else 'Brak kontekstu'}...")
            
            # Wy≈õwietl streszczenie ca≈Çej historii
            if len(context) > 0:
                user_questions = [msg['content'][:50] + "..." for msg in context if msg['role'] == 'user']
                print(f"üìã Wszystkie pytania u≈ºytkownika w sesji ({len(user_questions)}):")
                for i, q in enumerate(user_questions, 1):
                    print(f"   {i}. {q}")
            
            for msg in recent_context:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
                
            # Dodaj szczeg√≥≈Çowe instrukcje dotyczƒÖce kontekstu sesji
            context_instruction = ""
            if len(context) > 1:  # Je≈õli jest historia rozmowy
                first_question = context[0]['content'] if context[0]['role'] == 'user' else "Brak pierwszego pytania"
                context_instruction = f"""
                
                üö® PRZYPOMNIENIE: ODPOWIADASZ WY≈ÅƒÑCZNIE NA PYTANIA LOTNICZE!
                
                WA≈ªNE INSTRUKCJE DOTYCZƒÑCE KONTEKSTU SESJI:
                - Pamiƒôtaj, ≈ºe to kontynuacja rozmowy - przeanalizuj ca≈ÇƒÖ historiƒô powy≈ºej
                - Pierwsze pytanie u≈ºytkownika w tej sesji to: "{first_question}"
                - Je≈õli u≈ºytkownik pyta o co≈õ, co by≈Ço wcze≈õniej omawiane, odwo≈Çaj siƒô do tego
                - Je≈õli u≈ºytkownik pyta o pierwsze pytanie, odpowiedz konkretnie
                - Zachowaj sp√≥jno≈õƒá ze stylem odpowiedzi preferowanym przez u≈ºytkownika
                - NawiƒÖzuj do wcze≈õniejszych temat√≥w gdy to w≈Ça≈õciwe
                
                üõë SPRAWD≈π CZY PYTANIE DOTYCZY LOTNICTWA:
                Je≈õli pytanie poni≈ºej NIE dotyczy lotnictwa, awioniki, przepis√≥w lotniczych, nawigacji lotniczej, meteorologii lotniczej, bezpiecze≈Ñstwa lot√≥w lub zwiƒÖzanych temat√≥w, odpowiedz DOK≈ÅADNIE standardowƒÖ formu≈ÇƒÖ odmowy.
                
                AKTUALNE PYTANIE: {query}
                """
            else:
                context_instruction = f"""
                
                üö® PRZYPOMNIENIE: ODPOWIADASZ WY≈ÅƒÑCZNIE NA PYTANIA LOTNICZE!
                
                üõë SPRAWD≈π CZY PYTANIE DOTYCZY LOTNICTWA:
                Je≈õli pytanie poni≈ºej NIE dotyczy lotnictwa, awioniki, przepis√≥w lotniczych, nawigacji lotniczej, meteorologii lotniczej, bezpiecze≈Ñstwa lot√≥w lub zwiƒÖzanych temat√≥w, odpowiedz DOK≈ÅADNIE standardowƒÖ formu≈ÇƒÖ odmowy.
                
                PYTANIE: {query}
                """
            
            # Kombinuj prompt uczenia z instrukcjami kontekstu
            final_query = context_instruction
            if learning_prompt:
                final_query = f"{learning_prompt}\n\n{context_instruction}"
            
            # Dodaj aktualne pytanie z promptem uczenia
            messages.append({
                "role": "user",
                "content": final_query
            })
            
            print(f"üîç Przygotowano {len(messages)} wiadomo≈õci w kontek≈õcie (z promptem uczenia)")
            
            # Utw√≥rz wƒÖtek
            print(f"üîç Tworzƒô wƒÖtek z asystentem {self.assistant_id}")
            
            thread_data = {
                "messages": messages
            }
            
            # Dodaj vector store tylko je≈õli istnieje
            if vector_store_id:
                thread_data["tool_resources"] = {
                    "file_search": {
                        "vector_store_ids": [vector_store_id]
                    }
                }
            
            thread = self.client.beta.threads.create(**thread_data)
            
            print(f"üîç WƒÖtek utworzony: {thread.id}")
            
            # Uruchom asystenta z dodatkowym zabezpieczeniem i retry
            print(f"üîç Uruchamiam asystenta w trybie strumieniowym...")
            
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    # Sprawd≈∫ czy wƒÖtek ma aktywne runy i je anuluj
                    self.cancel_active_runs(thread.id)
                    
                    # Przygotuj parametry dla run
                    run_params = {
                        'thread_id': thread.id,
                        'assistant_id': self.assistant_id,
                        'stream': True,
                        'max_completion_tokens': 4000  # Ograniczenie d≈Çugo≈õci odpowiedzi
                    }
                    
                    # Dodaj temperature tylko je≈õli model go obs≈Çuguje
                    # Niekt√≥re modele (np. o1-preview, o3-mini) nie obs≈ÇugujƒÖ temperature
                    try:
                        run_params['temperature'] = 0.7
                        run = self.client.beta.threads.runs.create(**run_params)
                    except Exception as temp_error:
                        print(f"‚ö†Ô∏è  Model nie obs≈Çuguje temperature, u≈ºywam bez tego parametru: {temp_error}")
                        # Usu≈Ñ temperature i spr√≥buj ponownie
                        run_params.pop('temperature', None)
                        run = self.client.beta.threads.runs.create(**run_params)
                    
                    # Przetw√≥rz strumie≈Ñ odpowiedzi
                    response_text = ""
                    chunk_count = 0
                    stream_failed = False
                
                    for event in run:
                        if event.event == 'thread.message.delta':
                            if hasattr(event.data, 'delta') and hasattr(event.data.delta, 'content'):
                                for content in event.data.delta.content:
                                    if content.type == 'text' and hasattr(content.text, 'value'):
                                        chunk = content.text.value
                                        response_text += chunk
                                        chunk_count += 1
                                        if chunk_count <= 3:  # Loguj tylko pierwsze 3 chunki
                                            print(f"üîç Otrzymano chunk #{chunk_count}: {chunk[:30]}...")
                                        yield chunk
                        elif event.event == 'thread.run.completed':
                            print("‚úÖ Uko≈Ñczono generowanie odpowiedzi")
                            break
                        elif event.event == 'thread.run.failed':
                            error_details = getattr(event.data, 'last_error', None)
                            if error_details:
                                error_msg = f"OpenAI API Error: {error_details.code} - {error_details.message}"
                                print(f"‚ùå {error_msg}")
                                stream_failed = True
                                if retry_count < max_retries - 1:
                                    print(f"üîÑ Pr√≥bujƒô ponownie ({retry_count + 1}/{max_retries})...")
                                    break
                                else:
                                    yield f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd po stronie OpenAI: {error_details.message}. Spr√≥buj ponownie za chwilƒô."
                            else:
                                print(f"‚ùå B≈ÇƒÖd podczas generowania: {event.data}")
                                stream_failed = True
                                if retry_count < max_retries - 1:
                                    print(f"üîÑ Pr√≥bujƒô ponownie ({retry_count + 1}/{max_retries})...")
                                    break
                                else:
                                    yield "Przepraszam, wystƒÖpi≈Ç nieoczekiwany b≈ÇƒÖd. Spr√≥buj ponownie."
                            break
                        elif event.event == 'thread.run.cancelled':
                            print("‚ö†Ô∏è Generowanie zosta≈Ço anulowane")
                            yield "Generowanie odpowiedzi zosta≈Ço anulowane."
                            return
                    
                    # Je≈õli nie by≈Ço b≈Çƒôdu, zako≈Ñcz retry loop
                    if not stream_failed:
                        print(f"üîç Otrzymano ≈ÇƒÖcznie {chunk_count} chunk√≥w, d≈Çugo≈õƒá odpowiedzi: {len(response_text)}")
                        break
                        
                except Exception as stream_error:
                    print(f"‚ùå B≈ÇƒÖd podczas streamowania: {stream_error}")
                    if retry_count < max_retries - 1:
                        print(f"üîÑ Pr√≥bujƒô ponownie ({retry_count + 1}/{max_retries})...")
                        retry_count += 1
                        time.sleep(2 ** retry_count)  # Exponential backoff
                        continue
                    else:
                        yield f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd podczas generowania odpowiedzi: {str(stream_error)}"
                        break
                
                retry_count += 1
                if stream_failed and retry_count < max_retries:
                    time.sleep(2 ** retry_count)  # Exponential backoff
            
            # Poczekaj na zako≈Ñczenie
            time.sleep(1)
            
            # Usu≈Ñ tymczasowe zasoby
            self.cleanup_resources(vector_store_id, file_ids, thread.id)
            print(f"üîç Zako≈Ñczono generowanie odpowiedzi")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas generowania odpowiedzi: {str(e)}")
            import traceback
            traceback.print_exc()
            yield f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd: {str(e)}"
    
    def cleanup_resources(self, vector_store_id, file_ids, thread_id):
        """Usuwa tymczasowe zasoby"""
        try:
            # Usu≈Ñ pliki
            for file_id in file_ids:
                try:
                    self.client.files.delete(file_id)
                except:
                    pass
            
            # Usu≈Ñ vector store
            if vector_store_id:
                try:
                    self.client.beta.vector_stores.delete(vector_store_id)
                except:
                    pass
            
            # Usu≈Ñ wƒÖtek
            if thread_id:
                try:
                    self.client.beta.threads.delete(thread_id)
                except:
                    pass
                    
        except Exception as e:
            print(f"B≈ÇƒÖd podczas usuwania zasob√≥w: {str(e)}")
    
    def generate_pdf_report(self, content, session_id, message_id=None):
        """Generuje raport PDF z odpowiedzi"""
        try:
            # Utw√≥rz katalog dla sesji
            reports_dir = f'reports/{session_id}'
            os.makedirs(reports_dir, exist_ok=True)
            
            # Nazwa pliku PDF
            if message_id:
                filename = f'answer_{message_id}.pdf'
            else:
                filename = f'answer_{int(time.time())}.pdf'
            
            filepath = os.path.join(reports_dir, filename)
            
            # Utw√≥rz dokument PDF
            doc = SimpleDocTemplate(filepath, pagesize=A4)
            
            # Style
            styles = getSampleStyleSheet()
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontSize=18,
                alignment=TA_CENTER,
                spaceAfter=30
            )
            
            normal_style = ParagraphStyle(
                'CustomNormal',
                parent=styles['Normal'],
                fontSize=12,
                alignment=TA_JUSTIFY,
                spaceAfter=12
            )
            
            # Tre≈õƒá dokumentu
            story = []
            
            # Tytu≈Ç
            story.append(Paragraph("Aero-Chat - Raport Odpowiedzi", title_style))
            story.append(Spacer(1, 12))
            
            # Data
            story.append(Paragraph(f"Data: {datetime.now().strftime('%d.%m.%Y %H:%M')}", normal_style))
            story.append(Paragraph(f"Sesja: {session_id}", normal_style))
            story.append(Spacer(1, 20))
            
            # Odpowied≈∫
            story.append(Paragraph("Odpowied≈∫:", styles['Heading2']))
            
            # Podziel tre≈õƒá na akapity
            paragraphs = content.split('\n\n')
            for para in paragraphs:
                if para.strip():
                    story.append(Paragraph(para.strip(), normal_style))
            
            # Zbuduj PDF
            doc.build(story)
            
            return filepath
            
        except Exception as e:
            print(f"B≈ÇƒÖd podczas generowania PDF: {str(e)}")
            return None
    
    def add_feedback_to_training(self, feedback_data):
        """Dodaje feedback do bazy wiedzy asystenta"""
        try:
            # Zapisz feedback w specjalnym katalogu treningowym
            training_dir = 'training_data'
            os.makedirs(training_dir, exist_ok=True)
            
            # Stw√≥rz nazwƒô pliku bazujƒÖc na typie sekcji i timestampie
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'feedback_{feedback_data["section_type"]}_{timestamp}.json'
            filepath = os.path.join(training_dir, filename)
            
            # Przygotuj dane treningowe
            training_data = {
                'feedback_type': feedback_data['feedback_type'],
                'section_type': feedback_data['section_type'],
                'content': feedback_data['content'],
                'user_description': feedback_data['description'],
                'timestamp': feedback_data['timestamp'],
                'session_id': feedback_data['session_id'],
                'improvement_notes': self.generate_improvement_notes(feedback_data)
            }
            
            # Zapisz do pliku JSON
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Feedback dodany do bazy treningowej: {filename}")
            
            # Je≈õli feedback jest negatywny, spr√≥buj poprawiƒá odpowied≈∫
            if feedback_data['feedback_type'] == 'negative':
                self.process_negative_feedback(feedback_data)
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas dodawania feedback do treningu: {str(e)}")
    
    def generate_improvement_notes(self, feedback_data):
        """Generuje notatki o poprawach na podstawie feedbacku"""
        notes = []
        
        if feedback_data['feedback_type'] == 'negative':
            notes.append("Tre≈õƒá wymaga poprawy wed≈Çug u≈ºytkownika")
            if feedback_data['description']:
                notes.append(f"Uwagi u≈ºytkownika: {feedback_data['description']}")
                
            # Dodaj sugestie poprawy na podstawie typu sekcji
            if feedback_data['section_type'] == 'header':
                notes.append("Rozwa≈º zmianƒô struktury nag≈Ç√≥wka lub jego tre≈õci")
            elif feedback_data['section_type'] == 'paragraph':
                notes.append("Rozwa≈º przepisanie akapitu dla lepszej jasno≈õci")
            elif feedback_data['section_type'] == 'list':
                notes.append("Rozwa≈º zmianƒô struktury listy lub jej element√≥w")
        else:
            notes.append("Tre≈õƒá uznana za przydatnƒÖ przez u≈ºytkownika")
            if feedback_data['description']:
                notes.append(f"Pozytywne uwagi: {feedback_data['description']}")
        
        return notes
    
    def process_negative_feedback(self, feedback_data):
        """Przetwarza negatywny feedback i pr√≥buje poprawiƒá przysz≈Çe odpowiedzi"""
        try:
            # Zapisz do pliku z negatywnymi feedbackami
            negative_feedback_file = 'training_data/negative_feedback_summary.json'
            
            # Wczytaj istniejƒÖce negatywne feedbacki
            if os.path.exists(negative_feedback_file):
                with open(negative_feedback_file, 'r', encoding='utf-8') as f:
                    all_negative = json.load(f)
            else:
                all_negative = []
            
            # Dodaj nowy feedback
            all_negative.append({
                'content': feedback_data['content'],
                'description': feedback_data['description'],
                'section_type': feedback_data['section_type'],
                'timestamp': feedback_data['timestamp']
            })
            
            # Zapisz z powrotem
            with open(negative_feedback_file, 'w', encoding='utf-8') as f:
                json.dump(all_negative, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Negatywny feedback dodany do analizy: {feedback_data['section_type']}")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas przetwarzania negatywnego feedbacku: {str(e)}")

    def get_training_insights(self):
        """Pobiera insights z feedbacku treningowego"""
        try:
            training_dir = 'training_data'
            if not os.path.exists(training_dir):
                return {}
            
            insights = {
                'total_feedback': 0,
                'positive_feedback': 0,
                'negative_feedback': 0,
                'section_types': {},
                'common_issues': []
            }
            
            # Przeanalizuj wszystkie pliki feedbacku
            for filename in os.listdir(training_dir):
                if filename.startswith('feedback_') and filename.endswith('.json'):
                    filepath = os.path.join(training_dir, filename)
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                        insights['total_feedback'] += 1
                        
                        if data['feedback_type'] == 'positive':
                            insights['positive_feedback'] += 1
                        else:
                            insights['negative_feedback'] += 1
                        
                        # Statystyki typ√≥w sekcji
                        section_type = data['section_type']
                        if section_type not in insights['section_types']:
                            insights['section_types'][section_type] = {'positive': 0, 'negative': 0}
                        insights['section_types'][section_type][data['feedback_type']] += 1
            
            return insights
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas pobierania insights: {str(e)}")
            return {}
    
    def save_conversation_context(self, session_id, context, current_message):
        """Zapisuje kontekst rozmowy do pliku dla debugowania i uczenia siƒô"""
        try:
            os.makedirs('history', exist_ok=True)
            context_file = f'history/{session_id}_full_context.json'
            
            # Przygotuj strukturƒô do zapisu
            conversation_data = {
                'timestamp': datetime.now().isoformat(),
                'session_id': session_id,
                'total_messages': len(context),
                'current_message': current_message,
                'full_conversation': context,
                'summary': {
                    'user_messages': len([m for m in context if m['role'] == 'user']),
                    'assistant_messages': len([m for m in context if m['role'] == 'assistant']),
                    'last_3_messages': context[-3:] if len(context) >= 3 else context
                }
            }
            
            with open(context_file, 'w', encoding='utf-8') as f:
                json.dump(conversation_data, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ Kontekst rozmowy zapisany do {context_file}")
            print(f"üìä Statystyki: {conversation_data['summary']}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  B≈ÇƒÖd zapisu kontekstu rozmowy: {e}")

    def load_conversation_context(self, session_id):
        """≈Åaduje kontekst rozmowy z pliku"""
        try:
            context_file = f'history/{session_id}_full_context.json'
            if os.path.exists(context_file):
                with open(context_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                return data.get('full_conversation', [])
            return []
        except Exception as e:
            print(f"‚ö†Ô∏è  B≈ÇƒÖd ≈Çadowania kontekstu rozmowy: {e}")
            return []
    
    def is_aviation_related(self, query: str) -> bool:
        """Sprawdza czy pytanie dotyczy lotnictwa"""
        aviation_keywords = [
            # Polskie terminy lotnicze
            'lotnictwo', 'pilot', 'samolot', '≈õmig≈Çowiec', 'helikopter', 'szybowiec',
            'silnik', 'skrzyd≈Ço', 'kad≈Çub', 'usterzenie', 'podwozie', 'aerodynamika',
            'si≈Ça no≈õna', 'op√≥r', 'ciƒÖg', 'lot', 'lƒÖdowanie', 'start', 'wzlot',
            'nawigacja', 'GPS', 'radar', 'radio', 'komunikacja', 'wie≈ºa', 'kontrola',
            'meteorologia', 'pogoda', 'turbulencje', 'wiatr', 'chmury', 'widoczno≈õƒá',
            'ICAO', 'EASA', 'FAA', 'ULC', 'przepisy', 'certyfikacja', 'licencja',
            'VFR', 'IFR', 'ATPL', 'PPL', 'CPL', 'IR', 'MEP', 'SEP',
            'lotnisko', 'pas', 'tower', 'hangar', 'terminal', 'ramp',
            'awionika', 'autopilot', 'transponder', 'altimetr', 'prƒôdko≈õciomierz',
            'bezpiecze≈Ñstwo', 'wypadek', 'incydent', '≈õledztwo', 'raport',
            'szkolenie', 'instruktor', 'egzamin', 'kurs', 'symulator',
            'maintenance', 'przeglƒÖd', 'naprawa', 'serwis', 'czƒô≈õci',
            'paliwo', 'tankowanie', 'masa', 'balans', '≈õrodek ciƒô≈ºko≈õci',
            'przestrze≈Ñ', 'powietrzna', 'trasa', 'plan', 'lotu',
            
            # Angielskie terminy lotnicze
            'aviation', 'aircraft', 'airplane', 'helicopter', 'glider', 'pilot',
            'engine', 'wing', 'fuselage', 'landing', 'takeoff', 'flight',
            'navigation', 'weather', 'airport', 'runway', 'control', 'tower',
            'avionics', 'autopilot', 'altimeter', 'airspeed', 'attitude',
            'VOR', 'NDB', 'ILS', 'DME', 'ADF', 'HSI', 'CDI',
            'turbulence', 'ceiling', 'visibility', 'crosswind', 'headwind',
            'approach', 'departure', 'cruise', 'descent', 'climb',
            'checklist', 'procedure', 'emergency', 'malfunction', 'failure',
            'certification', 'training', 'instructor', 'student', 'solo',
            'ground', 'school', 'simulator', 'logbook', 'hours',
            'maintenance', 'inspection', 'repair', 'overhaul', 'AD',
            'airworthiness', 'registration', 'insurance', 'hangar',
            'fuel', 'weight', 'balance', 'loading', 'performance',
            'aerodynamics', 'lift', 'drag', 'thrust', 'stall'
        ]
        
        # Sprawd≈∫ czy pytanie zawiera s≈Çowa kluczowe lotnicze
        query_lower = query.lower()
        for keyword in aviation_keywords:
            if keyword in query_lower:
                return True
        
        # Sprawd≈∫ czy pytanie zawiera typowe frazesy lotnicze
        aviation_phrases = [
            'jak dzia≈Ça', 'co to jest', 'zasada', 'procedura', 'jak wykonaƒá',
            'jakie sƒÖ', 'kiedy', 'gdzie', 'dlaczego', 'w lotnictwie',
            'w samolocie', 'podczas lotu', 'na lotnisku', 'w powietrzu',
            'pilot', 'kontroler', 'mechanik', 'instruktor', 'egzaminator'
        ]
        
        for phrase in aviation_phrases:
            if phrase in query_lower:
                # Je≈õli zawiera frazƒô lotniczƒÖ, sprawd≈∫ kontekst
                for keyword in aviation_keywords:
                    if keyword in query_lower:
                        return True
        
        return False
